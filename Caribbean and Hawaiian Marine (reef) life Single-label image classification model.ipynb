{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Caribbean and Hawaiian Marine (Reef) Life Image Classification Capstone Project\n",
    "### Ryan Johnson"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project Overview\n",
    "As an avid snorkeler and someone who has always been interested in the unique Marine reef life ecosystem that exists within the water, I have taken many trips to explore reefs in the ocean and taken enormous amounts of images underwater. Still, I am always at a loss for what I am taking an image of; some marine life creatures I know quite well, including a green sea turtle, but others I am at a complete loss in identifying. The image classification model will create a system in which I can upload distinct sea creatures, and the model can properly identify and allow me to know what exactly I am looking at without needing a guide key to identify different underwater animals and fish that exist. The image classification model is simply a way to speed up my comprehension of the underwater creatures and ecosystems I have explored and identify what the sea creatures are when snorkeling in the ocean with my GoPro when taking enormous amounts of pictures and videos.\n",
    "\n",
    "### Problem Statement\n",
    "My capstone project aims to create a Caribbean and Hawaiian Marine (reef) life Single-label image classification model to identify different sea creatures, including sea animals and fish. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Caribbean and Hawaiian Marine (Reef) Life Image Classification (Single Label)\n",
    "The five sea creatures and fish labels I have include:\n",
    "* Cuttlefish\n",
    "* Eagle ray\n",
    "* Green Sea Turtle\n",
    "* Reef triggerfish\n",
    "* Stingray\n",
    "\n",
    "Each of these classes of sea creatures has over 65 images and are a distinct sea creature for creating the single-label image classification model. I took these pictures using my GoPro when snorkeling in the Caribbean and Hawaiian oceans from 2017 to 2025. For my GoPro I have filter lens that help me take a clear image underwater, that is my some of the images have a warming color tone than others. I have 1162 images in total. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When creating the image classification dataset and annotating the images into each of the label classes there are:\n",
    "* Cuttlefish- 65 images\n",
    "* Eagle ray- 366 images\n",
    "* Green Sea Turtle- 482 images\n",
    "* Reef triggerfish- 67 images\n",
    "* Stingray- 182 images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# tensorflow\n",
    "import tensorflow as tf\n",
    "\n",
    "# to build dataset in tensorflow need use datasets\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "#import torchvision.transforms as transforms\n",
    "\n",
    "import sys\n",
    "import os\n",
    "from os import listdir\n",
    "\n",
    "import PIL # Python Imaging Library\n",
    "from IPython.display import display # Display Images\n",
    "import pathlib\n",
    "\n",
    "import random # to set the seed\n",
    "\n",
    "# confusion_matrix, classification_report\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Roboflow's API to Download Dataset into GitHub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: roboflow in c:\\users\\rthom\\appdata\\roaming\\python\\python311\\site-packages (1.1.32)\n",
      "Requirement already satisfied: certifi==2023.7.22 in c:\\users\\rthom\\appdata\\roaming\\python\\python311\\site-packages (from roboflow) (2023.7.22)\n",
      "Requirement already satisfied: chardet==4.0.0 in c:\\users\\rthom\\anaconda3\\lib\\site-packages (from roboflow) (4.0.0)\n",
      "Requirement already satisfied: cycler==0.10.0 in c:\\users\\rthom\\appdata\\roaming\\python\\python311\\site-packages (from roboflow) (0.10.0)\n",
      "Requirement already satisfied: idna==2.10 in c:\\users\\rthom\\appdata\\roaming\\python\\python311\\site-packages (from roboflow) (2.10)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\rthom\\anaconda3\\lib\\site-packages (from roboflow) (1.4.4)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\rthom\\anaconda3\\lib\\site-packages (from roboflow) (3.8.0)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\rthom\\anaconda3\\lib\\site-packages (from roboflow) (1.24.3)\n",
      "Requirement already satisfied: opencv-python-headless==4.8.0.74 in c:\\users\\rthom\\anaconda3\\lib\\site-packages (from roboflow) (4.8.0.74)\n",
      "Requirement already satisfied: Pillow>=7.1.2 in c:\\users\\rthom\\anaconda3\\lib\\site-packages (from roboflow) (10.2.0)\n",
      "Requirement already satisfied: python-dateutil in c:\\users\\rthom\\anaconda3\\lib\\site-packages (from roboflow) (2.8.2)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\rthom\\anaconda3\\lib\\site-packages (from roboflow) (0.21.0)\n",
      "Requirement already satisfied: requests in c:\\users\\rthom\\anaconda3\\lib\\site-packages (from roboflow) (2.31.0)\n",
      "Requirement already satisfied: six in c:\\users\\rthom\\anaconda3\\lib\\site-packages (from roboflow) (1.16.0)\n",
      "Requirement already satisfied: urllib3>=1.26.6 in c:\\users\\rthom\\anaconda3\\lib\\site-packages (from roboflow) (2.0.7)\n",
      "Requirement already satisfied: tqdm>=4.41.0 in c:\\users\\rthom\\anaconda3\\lib\\site-packages (from roboflow) (4.65.0)\n",
      "Requirement already satisfied: PyYAML>=5.3.1 in c:\\users\\rthom\\anaconda3\\lib\\site-packages (from roboflow) (6.0.1)\n",
      "Requirement already satisfied: requests-toolbelt in c:\\users\\rthom\\anaconda3\\lib\\site-packages (from roboflow) (1.0.0)\n",
      "Requirement already satisfied: python-magic in c:\\users\\rthom\\anaconda3\\lib\\site-packages (from roboflow) (0.4.27)\n",
      "Requirement already satisfied: colorama in c:\\users\\rthom\\anaconda3\\lib\\site-packages (from tqdm>=4.41.0->roboflow) (0.4.6)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\rthom\\anaconda3\\lib\\site-packages (from matplotlib->roboflow) (1.2.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\rthom\\anaconda3\\lib\\site-packages (from matplotlib->roboflow) (4.25.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\rthom\\anaconda3\\lib\\site-packages (from matplotlib->roboflow) (23.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\rthom\\anaconda3\\lib\\site-packages (from matplotlib->roboflow) (3.0.9)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\rthom\\anaconda3\\lib\\site-packages (from requests->roboflow) (2.0.4)\n",
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Dataset Version Zip in Caribbean-and-Hawaii-Marine-Life-1 to folder:: 100%|██████████| 51207/51207 [00:11<00:00, 4637.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting Dataset Version Zip to Caribbean-and-Hawaii-Marine-Life-1 in folder:: 100%|██████████| 1182/1182 [00:00<00:00, 2322.45it/s]\n"
     ]
    }
   ],
   "source": [
    "!pip install roboflow\n",
    "\n",
    "from roboflow import Roboflow\n",
    "rf = Roboflow(api_key=\"jleFsz2VdsZFEDQDayOM\")\n",
    "project = rf.workspace(\"protozoa\").project(\"caribbean-and-hawaii-marine-life\")\n",
    "version = project.version(1)\n",
    "dataset = version.download(\"folder\")\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Caribbean-and-Hawaii-Marine-Life-1 version 1 dataset path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rthom\\Documents\\GitHub\\Caribbean-and-Hawaiian-Marine-Reef-Life-Image-Classification\\Caribbean-and-Hawaii-Marine-Life-1\n"
     ]
    }
   ],
   "source": [
    "# Caribbean-and-Hawaii-Marine-Life-1 version 1 dataset path\n",
    "dataset_path = dataset.location  # folder where the dataset is downloaded\n",
    "\n",
    "print(dataset_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train, Valid, and Test Dataset Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rthom\\Documents\\GitHub\\Caribbean-and-Hawaiian-Marine-Reef-Life-Image-Classification\\Caribbean-and-Hawaii-Marine-Life-1\\test\n",
      "C:\\Users\\rthom\\Documents\\GitHub\\Caribbean-and-Hawaiian-Marine-Reef-Life-Image-Classification\\Caribbean-and-Hawaii-Marine-Life-1\\train\n",
      "C:\\Users\\rthom\\Documents\\GitHub\\Caribbean-and-Hawaiian-Marine-Reef-Life-Image-Classification\\Caribbean-and-Hawaii-Marine-Life-1\\valid\n"
     ]
    }
   ],
   "source": [
    "folder_paths_tvt = []\n",
    "for root, directs, files in os.walk(dataset_path):\n",
    "    for direct in directs:\n",
    "        folder_paths.append(os.path.join(root, direct))\n",
    "\n",
    "# Print the folder paths\n",
    "for folder_path in folder_paths[0:3]:\n",
    "    print(folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Data Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data Path:\n",
      "C:\\Users\\rthom\\Documents\\GitHub\\Caribbean-and-Hawaiian-Marine-Reef-Life-Image-Classification\\Caribbean-and-Hawaii-Marine-Life-1\\train\n"
     ]
    }
   ],
   "source": [
    "train_data_path = folder_paths[1]\n",
    "print(f'Train Data Path:\\n{train_data_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Valid Data Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid Data Path:\n",
      "C:\\Users\\rthom\\Documents\\GitHub\\Caribbean-and-Hawaiian-Marine-Reef-Life-Image-Classification\\Caribbean-and-Hawaii-Marine-Life-1\\valid\n"
     ]
    }
   ],
   "source": [
    "valid_data_path = folder_paths[2]\n",
    "print(f'Valid Data Path:\\n{valid_data_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Data Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Data Path:\n",
      "C:\\Users\\rthom\\Documents\\GitHub\\Caribbean-and-Hawaiian-Marine-Reef-Life-Image-Classification\\Caribbean-and-Hawaii-Marine-Life-1\\test\n"
     ]
    }
   ],
   "source": [
    "test_data_path = folder_paths[0]\n",
    "print(f'Test Data Path:\\n{test_data_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Listed Directories from the Dataset (Folders for Each of the Classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "img_dir = dataset_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caribbean-and-Hawaii-Marine-Life-1/ (2 files)\n",
      "     test/ (0 files)\n",
      "          Cuttlefish/ (6 files)\n",
      "          Eagle ray/ (36 files)\n",
      "          Green Sea Turtle/ (48 files)\n",
      "          Reef triggerfish/ (7 files)\n",
      "          Stingray/ (17 files)\n",
      "     train/ (0 files)\n",
      "          Cuttlefish/ (46 files)\n",
      "          Eagle ray/ (260 files)\n",
      "          Green Sea Turtle/ (337 files)\n",
      "          Reef triggerfish/ (47 files)\n",
      "          Stingray/ (131 files)\n",
      "     valid/ (0 files)\n",
      "          Cuttlefish/ (13 files)\n",
      "          Eagle ray/ (70 files)\n",
      "          Green Sea Turtle/ (97 files)\n",
      "          Reef triggerfish/ (13 files)\n",
      "          Stingray/ (34 files)\n",
      "\n",
      "There are 1162 images in this dataset\n"
     ]
    }
   ],
   "source": [
    "total_files = 0\n",
    "# root, directory, files in the path of the folder\n",
    "for root, direc, files in os.walk(str(img_dir)):\n",
    "    \n",
    "    # spliting up the levels of folder files within the main folder\n",
    "    folder_levels = root.replace(str(img_dir), '').count(os.sep)\n",
    "    \n",
    "    # adding spacing to directories\n",
    "    spacing = ' ' * (folder_levels) * 5\n",
    "    \n",
    "    print(f'{spacing}{os.path.basename(root)}/ ({len(files)} files)')\n",
    "    total_files += len(files)\n",
    "    \n",
    "print()   \n",
    "print(f'There are {total_files -2} images in this dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating training validation, and test datasets for Caribbean and Hawaiian Marine Life Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting the seed to reproduce results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "set_seed = 123\n",
    "\n",
    "os.environ['PYTHONHASHSEED']=str(set_seed)\n",
    "os.environ['TF_CUDNN_DETERMINISTIC'] = '1'\n",
    "random.seed(set_seed)\n",
    "np.random.seed(set_seed)\n",
    "tf.random.set_seed(set_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading and Preprocessing Caribbean and Hawaiian Marine Life Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "image_height = 500 # the image is (500, 500)\n",
    "image_width = 500\n",
    "channels = 3 # Channel is (3) for RGB colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 821 files belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "train_data = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  train_data_path, # train folder contains all the folders contaning the 5 marine life creatures\n",
    "  labels='inferred', # labels are generated from the directory structure\n",
    "  label_mode='int', \n",
    "    \n",
    "    # 'categorical' causes errors needs to be 'int'\n",
    "    \n",
    "    #'int': means that the labels are encoded as integers (e.g. for sparse_categorical_crossentropy loss).\n",
    "    # 'categorical' means that the labels are encoded as a categorical vector (e.g. for categorical_crossentropy loss).\n",
    "    \n",
    "  #validation_split= train_test_split,\n",
    "  #subset=\"training\",\n",
    "  seed= set_seed, # seed is 123\n",
    "  image_size=(image_height, image_width),\n",
    "  batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 227 files belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "valid_data = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  valid_data_path, # valid folder contains all the folders contaning the 5 marine life creatures\n",
    "  labels='inferred', # labels are generated from the directory structure\n",
    "  label_mode='int', \n",
    "    # 'categorical' causes errors needs to be 'int'\n",
    "    \n",
    "    #'int': means that the labels are encoded as integers (e.g. for sparse_categorical_crossentropy loss).\n",
    "    # 'categorical' means that the labels are encoded as a categorical vector (e.g. for categorical_crossentropy loss).\n",
    "    \n",
    "  seed= set_seed, # seed is 123\n",
    "  image_size=(image_height, image_width),\n",
    "  batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 114 files belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "test_data = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  test_data_path, # test folder contains all the folders contaning the 5 marine life creatures\n",
    "  labels='inferred', # labels are generated from the directory structure\n",
    "  label_mode='int', \n",
    "    # 'categorical' causes errors needs to be 'int'\n",
    "    \n",
    "    #'int': means that the labels are encoded as integers (e.g. for sparse_categorical_crossentropy loss).\n",
    "    # 'categorical' means that the labels are encoded as a categorical vector (e.g. for categorical_crossentropy loss).\n",
    "    \n",
    "  seed= set_seed, # seed is 123\n",
    "  image_size=(image_height, image_width), # 500, 500\n",
    "  batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
