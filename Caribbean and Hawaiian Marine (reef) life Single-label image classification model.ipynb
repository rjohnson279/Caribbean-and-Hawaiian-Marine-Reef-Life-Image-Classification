{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Caribbean and Hawaiian Marine (Reef) Life Image Classification Capstone Project\n",
    "### Ryan Johnson"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project Overview\n",
    "As an avid snorkeler and someone who has always been interested in the unique Marine reef life ecosystem that exists within the water, I have taken many trips to explore reefs in the ocean and taken enormous amounts of images underwater. Still, I am always at a loss for what I am taking an image of; some marine life creatures I know quite well, including a green sea turtle, but others I am at a complete loss in identifying. The image classification model will create a system in which I can upload distinct sea creatures, and the model can properly identify and allow me to know what exactly I am looking at without needing a guide key to identify different underwater animals and fish that exist. The image classification model is simply a way to speed up my comprehension of the underwater creatures and ecosystems I have explored and identify what the sea creatures are when snorkeling in the ocean with my GoPro when taking enormous amounts of pictures and videos.\n",
    "\n",
    "### Problem Statement\n",
    "My capstone project aims to create a Caribbean and Hawaiian Marine (reef) life Single-label image classification model to identify different sea creatures, including sea animals and fish. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Caribbean and Hawaiian Marine (Reef) Life Image Classification (Single Label)\n",
    "The five sea creatures and fish labels I have include:\n",
    "* Cuttlefish\n",
    "* Eagle ray\n",
    "* Green Sea Turtle\n",
    "* Reef triggerfish\n",
    "* Stingray\n",
    "\n",
    "Each of these classes of sea creatures has over 65 images and are a distinct sea creature for creating the single-label image classification model. I took these pictures using my GoPro when snorkeling in the Caribbean and Hawaiian oceans from 2017 to 2025. For my GoPro I have filter lens that help me take a clear image underwater, that is my some of the images have a warming color tone than others. I have 1162 images in total. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When creating the image classification dataset and annotating the images into each of the label classes there are:\n",
    "* Cuttlefish- 65 images\n",
    "* Eagle ray- 366 images\n",
    "* Green Sea Turtle- 482 images\n",
    "* Reef triggerfish- 67 images\n",
    "* Stingray- 182 images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# tensorflow\n",
    "import tensorflow as tf\n",
    "\n",
    "# to build dataset in tensorflow need use datasets\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "#import torchvision.transforms as transforms\n",
    "\n",
    "import sys\n",
    "import os\n",
    "from os import listdir\n",
    "\n",
    "import PIL # Python Imaging Library\n",
    "from IPython.display import display # Display Images\n",
    "import pathlib\n",
    "\n",
    "import random # to set the seed\n",
    "\n",
    "# confusion_matrix, classification_report\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Roboflow's API to Download Dataset into GitHub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: roboflow in c:\\users\\rthom\\appdata\\roaming\\python\\python311\\site-packages (1.1.32)\n",
      "Requirement already satisfied: certifi==2023.7.22 in c:\\users\\rthom\\appdata\\roaming\\python\\python311\\site-packages (from roboflow) (2023.7.22)\n",
      "Requirement already satisfied: chardet==4.0.0 in c:\\users\\rthom\\anaconda3\\lib\\site-packages (from roboflow) (4.0.0)\n",
      "Requirement already satisfied: cycler==0.10.0 in c:\\users\\rthom\\appdata\\roaming\\python\\python311\\site-packages (from roboflow) (0.10.0)\n",
      "Requirement already satisfied: idna==2.10 in c:\\users\\rthom\\appdata\\roaming\\python\\python311\\site-packages (from roboflow) (2.10)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\rthom\\anaconda3\\lib\\site-packages (from roboflow) (1.4.4)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\rthom\\anaconda3\\lib\\site-packages (from roboflow) (3.8.0)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\rthom\\anaconda3\\lib\\site-packages (from roboflow) (1.24.3)\n",
      "Requirement already satisfied: opencv-python-headless==4.8.0.74 in c:\\users\\rthom\\anaconda3\\lib\\site-packages (from roboflow) (4.8.0.74)\n",
      "Requirement already satisfied: Pillow>=7.1.2 in c:\\users\\rthom\\anaconda3\\lib\\site-packages (from roboflow) (10.2.0)\n",
      "Requirement already satisfied: python-dateutil in c:\\users\\rthom\\anaconda3\\lib\\site-packages (from roboflow) (2.8.2)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\rthom\\anaconda3\\lib\\site-packages (from roboflow) (0.21.0)\n",
      "Requirement already satisfied: requests in c:\\users\\rthom\\anaconda3\\lib\\site-packages (from roboflow) (2.31.0)\n",
      "Requirement already satisfied: six in c:\\users\\rthom\\anaconda3\\lib\\site-packages (from roboflow) (1.16.0)\n",
      "Requirement already satisfied: urllib3>=1.26.6 in c:\\users\\rthom\\anaconda3\\lib\\site-packages (from roboflow) (2.0.7)\n",
      "Requirement already satisfied: tqdm>=4.41.0 in c:\\users\\rthom\\anaconda3\\lib\\site-packages (from roboflow) (4.65.0)\n",
      "Requirement already satisfied: PyYAML>=5.3.1 in c:\\users\\rthom\\anaconda3\\lib\\site-packages (from roboflow) (6.0.1)\n",
      "Requirement already satisfied: requests-toolbelt in c:\\users\\rthom\\anaconda3\\lib\\site-packages (from roboflow) (1.0.0)\n",
      "Requirement already satisfied: python-magic in c:\\users\\rthom\\anaconda3\\lib\\site-packages (from roboflow) (0.4.27)\n",
      "Requirement already satisfied: colorama in c:\\users\\rthom\\anaconda3\\lib\\site-packages (from tqdm>=4.41.0->roboflow) (0.4.6)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\rthom\\anaconda3\\lib\\site-packages (from matplotlib->roboflow) (1.2.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\rthom\\anaconda3\\lib\\site-packages (from matplotlib->roboflow) (4.25.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\rthom\\anaconda3\\lib\\site-packages (from matplotlib->roboflow) (23.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\rthom\\anaconda3\\lib\\site-packages (from matplotlib->roboflow) (3.0.9)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\rthom\\anaconda3\\lib\\site-packages (from requests->roboflow) (2.0.4)\n",
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n"
     ]
    }
   ],
   "source": [
    "!pip install roboflow\n",
    "\n",
    "from roboflow import Roboflow\n",
    "rf = Roboflow(api_key=\"jleFsz2VdsZFEDQDayOM\")\n",
    "project = rf.workspace(\"protozoa\").project(\"caribbean-and-hawaii-marine-life\")\n",
    "version = project.version(1)\n",
    "dataset = version.download(\"folder\")\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Caribbean-and-Hawaii-Marine-Life-1 version 1 dataset path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rthom\\Documents\\GitHub\\Caribbean-and-Hawaiian-Marine-Reef-Life-Image-Classification\\Caribbean-and-Hawaii-Marine-Life-1\n"
     ]
    }
   ],
   "source": [
    "# Caribbean-and-Hawaii-Marine-Life-1 version 1 dataset path\n",
    "dataset_path = dataset.location  # folder where the dataset is downloaded\n",
    "\n",
    "print(dataset_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train, Valid, and Test Dataset Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rthom\\Documents\\GitHub\\Caribbean-and-Hawaiian-Marine-Reef-Life-Image-Classification\\Caribbean-and-Hawaii-Marine-Life-1\\test\n",
      "c:\\Users\\rthom\\Documents\\GitHub\\Caribbean-and-Hawaiian-Marine-Reef-Life-Image-Classification\\Caribbean-and-Hawaii-Marine-Life-1\\train\n",
      "c:\\Users\\rthom\\Documents\\GitHub\\Caribbean-and-Hawaiian-Marine-Reef-Life-Image-Classification\\Caribbean-and-Hawaii-Marine-Life-1\\valid\n"
     ]
    }
   ],
   "source": [
    "folder_paths_tvt = []\n",
    "for root, directs, files in os.walk(dataset_path):\n",
    "    for direct in directs:\n",
    "        folder_paths_tvt.append(os.path.join(root, direct))\n",
    "\n",
    "# Print the folder paths\n",
    "for folder_path in folder_paths_tvt[0:3]:\n",
    "    print(folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Data Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data Path:\n",
      "c:\\Users\\rthom\\Documents\\GitHub\\Caribbean-and-Hawaiian-Marine-Reef-Life-Image-Classification\\Caribbean-and-Hawaii-Marine-Life-1\\train\n"
     ]
    }
   ],
   "source": [
    "train_data_path = folder_paths_tvt[1]\n",
    "print(f'Train Data Path:\\n{train_data_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Valid Data Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid Data Path:\n",
      "c:\\Users\\rthom\\Documents\\GitHub\\Caribbean-and-Hawaiian-Marine-Reef-Life-Image-Classification\\Caribbean-and-Hawaii-Marine-Life-1\\valid\n"
     ]
    }
   ],
   "source": [
    "valid_data_path = folder_paths_tvt[2]\n",
    "print(f'Valid Data Path:\\n{valid_data_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Data Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Data Path:\n",
      "c:\\Users\\rthom\\Documents\\GitHub\\Caribbean-and-Hawaiian-Marine-Reef-Life-Image-Classification\\Caribbean-and-Hawaii-Marine-Life-1\\test\n"
     ]
    }
   ],
   "source": [
    "test_data_path = folder_paths_tvt[0]\n",
    "print(f'Test Data Path:\\n{test_data_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Listed Directories from the Dataset (Folders for Each of the Classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "img_dir = dataset_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caribbean-and-Hawaii-Marine-Life-1/ (0 files)\n",
      "     test/ (0 files)\n",
      "          Cuttlefish/ (0 files)\n",
      "          Eagle ray/ (0 files)\n",
      "          Green Sea Turtle/ (0 files)\n",
      "          Reef triggerfish/ (0 files)\n",
      "          Stingray/ (0 files)\n",
      "     train/ (0 files)\n",
      "          Cuttlefish/ (0 files)\n",
      "          Eagle ray/ (0 files)\n",
      "          Green Sea Turtle/ (0 files)\n",
      "          Reef triggerfish/ (0 files)\n",
      "          Stingray/ (0 files)\n",
      "     valid/ (0 files)\n",
      "          Cuttlefish/ (0 files)\n",
      "          Eagle ray/ (0 files)\n",
      "          Green Sea Turtle/ (0 files)\n",
      "          Reef triggerfish/ (0 files)\n",
      "          Stingray/ (0 files)\n",
      "\n",
      "There are -2 images in this dataset\n"
     ]
    }
   ],
   "source": [
    "total_files = 0\n",
    "# root, directory, files in the path of the folder\n",
    "for root, direc, files in os.walk(str(img_dir)):\n",
    "    \n",
    "    # spliting up the levels of folder files within the main folder\n",
    "    folder_levels = root.replace(str(img_dir), '').count(os.sep)\n",
    "    \n",
    "    # adding spacing to directories\n",
    "    spacing = ' ' * (folder_levels) * 5\n",
    "    \n",
    "    print(f'{spacing}{os.path.basename(root)}/ ({len(files)} files)')\n",
    "    total_files += len(files)\n",
    "    \n",
    "print()   \n",
    "print(f'There are {total_files -2} images in this dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating training validation, and test datasets for Caribbean and Hawaiian Marine Life Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting the seed to reproduce results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "set_seed = 123\n",
    "\n",
    "os.environ['PYTHONHASHSEED']=str(set_seed)\n",
    "os.environ['TF_CUDNN_DETERMINISTIC'] = '1'\n",
    "random.seed(set_seed)\n",
    "np.random.seed(set_seed)\n",
    "tf.random.set_seed(set_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading and Preprocessing Caribbean and Hawaiian Marine Life Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "image_height = 500 # the image is (500, 500)\n",
    "image_width = 500\n",
    "channels = 3 # Channel is (3) for RGB colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 files belonging to 5 classes.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No images found in directory c:\\Users\\rthom\\Documents\\GitHub\\Caribbean-and-Hawaiian-Marine-Reef-Life-Image-Classification\\Caribbean-and-Hawaii-Marine-Life-1\\train. Allowed formats: ('.bmp', '.gif', '.jpeg', '.jpg', '.png')",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m train_data \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mpreprocessing\u001b[38;5;241m.\u001b[39mimage_dataset_from_directory(\n\u001b[0;32m      2\u001b[0m   train_data_path, \u001b[38;5;66;03m# train folder contains all the folders contaning the 5 marine life creatures\u001b[39;00m\n\u001b[0;32m      3\u001b[0m   labels\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minferred\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;66;03m# labels are generated from the directory structure\u001b[39;00m\n\u001b[0;32m      4\u001b[0m   label_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mint\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[0;32m      5\u001b[0m     \n\u001b[0;32m      6\u001b[0m     \u001b[38;5;66;03m# 'categorical' causes errors needs to be 'int'\u001b[39;00m\n\u001b[0;32m      7\u001b[0m     \n\u001b[0;32m      8\u001b[0m     \u001b[38;5;66;03m#'int': means that the labels are encoded as integers (e.g. for sparse_categorical_crossentropy loss).\u001b[39;00m\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;66;03m# 'categorical' means that the labels are encoded as a categorical vector (e.g. for categorical_crossentropy loss).\u001b[39;00m\n\u001b[0;32m     10\u001b[0m     \n\u001b[0;32m     11\u001b[0m   \u001b[38;5;66;03m#validation_split= train_test_split,\u001b[39;00m\n\u001b[0;32m     12\u001b[0m   \u001b[38;5;66;03m#subset=\"training\",\u001b[39;00m\n\u001b[0;32m     13\u001b[0m   seed\u001b[38;5;241m=\u001b[39m set_seed, \u001b[38;5;66;03m# seed is 123\u001b[39;00m\n\u001b[0;32m     14\u001b[0m   image_size\u001b[38;5;241m=\u001b[39m(image_height, image_width),\n\u001b[0;32m     15\u001b[0m   batch_size\u001b[38;5;241m=\u001b[39mbatch_size\n\u001b[0;32m     16\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\rthom\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\image_dataset.py:299\u001b[0m, in \u001b[0;36mimage_dataset_from_directory\u001b[1;34m(directory, labels, label_mode, class_names, color_mode, batch_size, image_size, shuffle, seed, validation_split, subset, interpolation, follow_links, crop_to_aspect_ratio, **kwargs)\u001b[0m\n\u001b[0;32m    295\u001b[0m image_paths, labels \u001b[38;5;241m=\u001b[39m dataset_utils\u001b[38;5;241m.\u001b[39mget_training_or_validation_split(\n\u001b[0;32m    296\u001b[0m     image_paths, labels, validation_split, subset\n\u001b[0;32m    297\u001b[0m )\n\u001b[0;32m    298\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m image_paths:\n\u001b[1;32m--> 299\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    300\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo images found in directory \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdirectory\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    301\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAllowed formats: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mALLOWLIST_FORMATS\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    302\u001b[0m     )\n\u001b[0;32m    304\u001b[0m dataset \u001b[38;5;241m=\u001b[39m paths_and_labels_to_dataset(\n\u001b[0;32m    305\u001b[0m     image_paths\u001b[38;5;241m=\u001b[39mimage_paths,\n\u001b[0;32m    306\u001b[0m     image_size\u001b[38;5;241m=\u001b[39mimage_size,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    312\u001b[0m     crop_to_aspect_ratio\u001b[38;5;241m=\u001b[39mcrop_to_aspect_ratio,\n\u001b[0;32m    313\u001b[0m )\n\u001b[0;32m    314\u001b[0m dataset \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mprefetch(tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mAUTOTUNE)\n",
      "\u001b[1;31mValueError\u001b[0m: No images found in directory c:\\Users\\rthom\\Documents\\GitHub\\Caribbean-and-Hawaiian-Marine-Reef-Life-Image-Classification\\Caribbean-and-Hawaii-Marine-Life-1\\train. Allowed formats: ('.bmp', '.gif', '.jpeg', '.jpg', '.png')"
     ]
    }
   ],
   "source": [
    "train_data = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  train_data_path, # train folder contains all the folders contaning the 5 marine life creatures\n",
    "  labels='inferred', # labels are generated from the directory structure\n",
    "  label_mode='int', \n",
    "    \n",
    "    # 'categorical' causes errors needs to be 'int'\n",
    "    \n",
    "    #'int': means that the labels are encoded as integers (e.g. for sparse_categorical_crossentropy loss).\n",
    "    # 'categorical' means that the labels are encoded as a categorical vector (e.g. for categorical_crossentropy loss).\n",
    "    \n",
    "  #validation_split= train_test_split,\n",
    "  #subset=\"training\",\n",
    "  seed= set_seed, # seed is 123\n",
    "  image_size=(image_height, image_width),\n",
    "  batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 227 files belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "valid_data = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  valid_data_path, # valid folder contains all the folders contaning the 5 marine life creatures\n",
    "  labels='inferred', # labels are generated from the directory structure\n",
    "  label_mode='int', \n",
    "    # 'categorical' causes errors needs to be 'int'\n",
    "    \n",
    "    #'int': means that the labels are encoded as integers (e.g. for sparse_categorical_crossentropy loss).\n",
    "    # 'categorical' means that the labels are encoded as a categorical vector (e.g. for categorical_crossentropy loss).\n",
    "    \n",
    "  seed= set_seed, # seed is 123\n",
    "  image_size=(image_height, image_width),\n",
    "  batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 114 files belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "test_data = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  test_data_path, # test folder contains all the folders contaning the 5 marine life creatures\n",
    "  labels='inferred', # labels are generated from the directory structure\n",
    "  label_mode='int', \n",
    "    # 'categorical' causes errors needs to be 'int'\n",
    "    \n",
    "    #'int': means that the labels are encoded as integers (e.g. for sparse_categorical_crossentropy loss).\n",
    "    # 'categorical' means that the labels are encoded as a categorical vector (e.g. for categorical_crossentropy loss).\n",
    "    \n",
    "  seed= set_seed, # seed is 123\n",
    "  image_size=(image_height, image_width), # 500, 500\n",
    "  batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
